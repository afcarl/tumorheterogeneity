{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates the data for the power analysis shown in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_power_graph_big(distances, S, ctc_min_size=1, ctc_max_size=2, significance_threshold=0.05):\n",
    "    \n",
    "    total_samples = distances.shape[0]\n",
    "    significance_count_neg = np.zeros(total_samples)\n",
    "    significance_count_pos = np.zeros(total_samples)\n",
    "\n",
    "    for n in range(2,total_samples):\n",
    "        for i in range(100):\n",
    "            sample_idx = random.sample(xrange(0,total_samples), n) # select indexes to look at\n",
    "            # column 2 contains all the CTCs we want to look at\n",
    "#             ctc_size_selection_idx = 2*np.ones(n) \n",
    "            sample_S = S[sample_idx].reshape(-1,1)\n",
    "            sample_distances = distances[sample_idx].reshape(-1,1)\n",
    "\n",
    "\n",
    "            # prepare for regression\n",
    "            sample_distances = sm.add_constant(sample_distances)\n",
    "            model = sm.OLS(sample_S, sample_distances)\n",
    "            results = model.fit()\n",
    "    #         print results.pvalues\n",
    "    #         print results.summary()\n",
    "            # do p-value calculations\n",
    "            p_value = results.pvalues[1]\n",
    "            \n",
    "            if results.params[1] > 0:\n",
    "                significance_count_pos[n] += int(p_value < significance_threshold)                \n",
    "            else:\n",
    "                significance_count_neg[n] += int(p_value < significance_threshold)                \n",
    "\n",
    "\n",
    "    significance_count_pos /= 100.0\n",
    "    significance_count_neg /= 100.0\n",
    "    \n",
    "    return {'pos':significance_count_pos.tolist(), 'neg':significance_count_neg.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ctc_min_size, ctc_max_size = 2, 7 \n",
    "# significance_threshold = 0.05\n",
    "\n",
    "# power_calculation\n",
    "\n",
    "def calculate_power_graph(distances, S, ctc_min_size=1, ctc_max_size=2, significance_threshold=0.05):\n",
    "    total_samples = distances.shape[0]\n",
    "    significance_count_neg = np.zeros(total_samples)\n",
    "    significance_count_pos = np.zeros(total_samples)\n",
    "\n",
    "    for n in range(2,total_samples):\n",
    "        for i in range(100):\n",
    "            sample_idx = np.random.randint(0,total_samples, size=n) # select indexes to look at\n",
    "            # select the CTC sizes to look at within the range\n",
    "            # using ctc_min_size-1 because the 0th column corresponds to the ctc of size 1\n",
    "            ctc_size_selection_idx = np.random.randint(ctc_min_size-1,ctc_max_size, size=n) \n",
    "            sample_S = S[sample_idx, ctc_size_selection_idx].reshape(-1,1)\n",
    "            sample_distances = distances[sample_idx].reshape(-1,1)\n",
    "\n",
    "\n",
    "            # prepare for regression\n",
    "            sample_distances = sm.add_constant(sample_distances)\n",
    "            model = sm.OLS(sample_S, sample_distances)\n",
    "            results = model.fit()\n",
    "            # do p-value calculations\n",
    "            try:\n",
    "                p_value = results.pvalues[1]\n",
    "                \n",
    "                if results.params[1] > 0:\n",
    "                    significance_count_pos[n] += int(p_value < significance_threshold)                \n",
    "                else:\n",
    "                    significance_count_neg[n] += int(p_value < significance_threshold)                \n",
    "\n",
    "            except IndexError as e:\n",
    "                print('Index error occured...')\n",
    "                print results.pvalues\n",
    "\n",
    "    significance_count_pos /= 100.0\n",
    "    significance_count_neg /= 100.0\n",
    "    \n",
    "    return {'pos':significance_count_pos.tolist(), 'neg':significance_count_neg.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FOLDER = '/Volumes/Stockage/u0.03simulations/1_0_02_outs_101/Dec2_pipe_out_Sun_Dec_18_21_02_27_2016/'\n",
    "\n",
    "S = np.load(FOLDER + 'S_list_ordered.npy')\n",
    "distances = np.load(FOLDER + 'deltas_ordered.npy')[:, 0]\n",
    "\n",
    "\n",
    "\n",
    "pow2001 = calculate_power_graph(distances,S,1,1,0.01)\n",
    "pow7001 = calculate_power_graph(distances,S,2,7,0.01)\n",
    "pow12001 = calculate_power_graph(distances,S,8,12,0.01)\n",
    "pow17001 = calculate_power_graph(distances,S,13,17,0.01)\n",
    "pow22001 = calculate_power_graph(distances,S,18,22,0.01)\n",
    "powbig001 = calculate_power_graph(distances,S,23,30,0.01)\n",
    "x = range(0,distances.shape[0])\n",
    "\n",
    "S_h = np.load(FOLDER + 'S_list01_big.npy')[:,3]\n",
    "distances_h = np.load(FOLDER + '/dist_01_big.npy')[:,3]\n",
    "\n",
    "powhuge001 = calculate_power_graph_big(distances_h,S_h,significance_threshold=0.01)\n",
    "x_h = range(0,distances_h.shape[0])\n",
    "\n",
    "powhuge001_10000 = powhuge001\n",
    "\n",
    "S_h = np.load(FOLDER + 'S_list01_big.npy')[:,1]\n",
    "distances_h = np.load(FOLDER + 'dist_01_big.npy')[:,1]\n",
    "\n",
    "powhuge001_1000 = calculate_power_graph_big(distances_h,S_h,significance_threshold=0.01)\n",
    "\n",
    "S_h = np.load(FOLDER + 'S_list01_big.npy')[:,0]\n",
    "distances_h = np.load(FOLDER + 'dist_01_big.npy')[:,0]\n",
    "\n",
    "powhuge001_100 = calculate_power_graph_big(distances_h,S_h,significance_threshold=0.01)\n",
    "\n",
    "# temporary use 'pos' for backward compatability\n",
    "power_plots = {\n",
    "    'pow2001':pow2001,\n",
    "    'pow7001':pow7001,\n",
    "    'pow12001':pow12001,\n",
    "    'pow17001':pow17001,\n",
    "    'pow22001':pow22001,\n",
    "    'powbig001':powbig001,\n",
    "    'powhuge10000':powhuge001_10000,\n",
    "    'powhuge1000':powhuge001_1000,\n",
    "    'powhuge100':powhuge001_100,\n",
    "    'x':x,\n",
    "    'x_h':x_h\n",
    "}\n",
    "\n",
    "json.dump(power_plots, open('./turnover_power.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FOLDER = '/Volumes/Stockage/u0.03simulations/1_0_0_outs_101/Dec2_pipe_out_Sun_Dec_18_09_36_53_2016/'\n",
    "\n",
    "S = np.load(FOLDER + 'S_list_ordered.npy')\n",
    "distances = np.load(FOLDER + 'deltas_ordered.npy')[:, 0]\n",
    "\n",
    "\n",
    "\n",
    "pow2001 = calculate_power_graph(distances,S,1,1,0.01)\n",
    "pow7001 = calculate_power_graph(distances,S,2,7,0.01)\n",
    "pow12001 = calculate_power_graph(distances,S,8,12,0.01)\n",
    "pow17001 = calculate_power_graph(distances,S,13,17,0.01)\n",
    "pow22001 = calculate_power_graph(distances,S,18,22,0.01)\n",
    "powbig001 = calculate_power_graph(distances,S,23,30,0.01)\n",
    "x = range(0,distances.shape[0])\n",
    "\n",
    "S_h = np.load(FOLDER + 'S_list01_big.npy')[:,3]\n",
    "distances_h = np.load(FOLDER + '/dist_01_big.npy')[:,3]\n",
    "\n",
    "powhuge001 = calculate_power_graph_big(distances_h,S_h,significance_threshold=0.01)\n",
    "x_h = range(0,distances_h.shape[0])\n",
    "\n",
    "powhuge001_10000 = powhuge001\n",
    "\n",
    "S_h = np.load(FOLDER + 'S_list01_big.npy')[:,1]\n",
    "distances_h = np.load(FOLDER + 'dist_01_big.npy')[:,1]\n",
    "\n",
    "powhuge001_1000 = calculate_power_graph_big(distances_h,S_h,significance_threshold=0.01)\n",
    "\n",
    "S_h = np.load(FOLDER + 'S_list01_big.npy')[:,0]\n",
    "distances_h = np.load(FOLDER + 'dist_01_big.npy')[:,0]\n",
    "\n",
    "powhuge001_100 = calculate_power_graph_big(distances_h,S_h,significance_threshold=0.01)\n",
    "\n",
    "\n",
    "# temporary use 'pos' for backward compatability\n",
    "power_plots = {\n",
    "    'pow2001':pow2001,\n",
    "    'pow7001':pow7001,\n",
    "    'pow12001':pow12001,\n",
    "    'pow17001':pow17001,\n",
    "    'pow22001':pow22001,\n",
    "    'powbig001':powbig001,\n",
    "    'powhuge10000':powhuge001_10000,\n",
    "    'powhuge1000':powhuge001_1000,\n",
    "    'powhuge100':powhuge001_100,\n",
    "    'x':x,\n",
    "    'x_h':x_h\n",
    "}\n",
    "\n",
    "json.dump(power_plots, open('./noturnover_power.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
